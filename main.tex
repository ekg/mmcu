\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{fontspec}
\setsansfont{Liberation Sans}
\geometry{
    a4paper,
    margin=2.5cm,
    includehead,
    includefoot
}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=black]{hyperref}
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{bbm}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\title{Memory makes computation universal, remember?}
\author{Erik Garrison\\
  \texttt{egarris5@uthsc.edu}\\[1ex]
  }
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Memory enables parallel systems to achieve universal computation.
This principle explains step-by-step reasoning in language models and complex computation in biological cells.
The key insight is that computational power comes from memory systems rather than processing complexity.
Current AI systems demonstrate this by learning to replicate human computational patterns through exposure to our written traces.
Their future development may depend more on improved memory architectures than on larger models.
This perspective offers a unified view of computation across minds, machines, and living systems.
\end{abstract}

\section{Introduction}
Even systems with very basic state transitions can achieve universal computation when equipped with memory \cite{merrill2023parallelism,peng2024limitations}.
This principle is demonstrated by remarkably minimal universal systems like Rule 110 cellular automata \cite{cook2004universality} and single-instruction computers \cite{savage1994space}.
We show how this fundamental insight manifests in computational systems ranging from neural networks to biological cells \cite{wang2023parallel}, where simple parallel operations combined with state maintenance enable complex computation \cite{swamy1983space,bisaz2024memory}.

Parallel architectures fundamentally constrain computational systems to threshold circuits.
Neural networks optimize for parallel processing to enable efficient training across multiple devices \cite{merrill2023parallelism,merrill2024}.
Cells operate through inherently parallel networks of molecular interactions, where each molecule functions as an independent process \cite{fu2023scgrn}.
Yet through mechanisms that maintain state across multiple steps---like chain-of-thought reasoning in language models \cite{wei2022chain,qiu2024ask} and molecular memory in cells \cite{hoel2020emergence}---these systems achieve complex sequential computation.
The power of this approach scales with memory capacity, as the computational capabilities gained depend crucially on the number of intermediate processing steps maintained \cite{merrill2024}.
From neural synapses to developmental patterns and genomic evolution, biological systems demonstrate how diverse memory structures enable complex information processing \cite{burrill2010making,espinosa2024molecular}.
In artificial systems, techniques like chain-of-thought prompting provide frameworks for memory-based recursive computation \cite{wei2022chain,dickson2024trust,ahn2024recursive}.
In both domains, universal computation emerges not through more sophisticated processing units, but through memory mechanisms that maintain and access computational state \cite{schuurmans2024autoregressive}.

We demonstrate how two basic capabilities---recursive state maintenance and reliable history access---are sufficient for universal computation \cite{bennett1989time,boyle2024memory}.
We first establish this formally through a constructive proof, grounding our subsequent analysis in computational theory.
We then examine how parallel processing limitations manifest in both artificial neural networks and biological systems, showing how these systems achieve complex computation through memory rather than sophisticated processing units.
Finally, we explore the practical implications for artificial intelligence development, particularly in the context of large language models and recursive reasoning.
This analysis provides a unified perspective on computation across domains while suggesting new directions for AI architecture development focused on robust state maintenance mechanisms.

\section{Basic requirements and construction}

A system has recursive state processing if it can read its current state $s$, generate an update function $f(s)$ that produces the next state, and maintain the new state $f(s)$ for subsequent processing \cite{manuri2019state}.
This state maintenance must be robust against errors and degradation \cite{yang2013survey}.

A system has reliable history access if it can: (1) reference any previous state $s_i$ from its computation history without error \cite{fu2024memory}, (2) distinguish between different states in its history unambiguously, (3) maintain and determine the correct temporal order of states \cite{berridge2014cell,pastor2020computation}, establishing clear boundaries between computational periods, and (4) guarantee the integrity of stored states \cite{lovkvist2021using}.
The system need not maintain its entire history in active memory, but when it accesses stored states, it must do so reliably and correctly.

This requirement for reliable history access naturally creates temporal structure in computation.
Different systems implement this in various ways---neural networks through attention windows and forward passes \cite{martini2015information,quentin2019differential}, cells through cell cycle phases and epigenetic mechanisms \cite{bruno2022epigenetic}, and organisms through developmental stages.
In each case, the system must maintain clear temporal boundaries to ensure reliable access to its computational history.

These capabilities enable universal computation through a straightforward construction \cite{deutsch1995universality,bennett1989time}.
Given a Universal Turing Machine $U$, we implement it as follows: The state $s = (q, p, a)$ encodes the current machine state $q$, the position $p$ of the tape head, and the symbol $a$ under the head.
At each step, the system processes current state $s$ to determine $(q', a', d) = \delta(q, a)$, where $q'$ is the next machine state, $a'$ is the symbol to write, and $d$ is the head movement.
It uses history access to reconstruct tape contents as needed and maintains the new state for the next step.

\section{Completeness of the construction}

The elegance of these requirements---recursive state maintenance and reliable history access---is demonstrated by a remarkably simple proof of their sufficiency for universal computation.
This proof provides the mathematical foundation for our broader discussion of computation across artificial and biological systems.
Its simplicity reinforces our central argument: universal computation emerges not from complex processing units, but from basic capabilities for maintaining and accessing computational state.

\vspace{1em}

\begin{theorem}[Completeness]
Any system $S$ with recursive state maintenance and reliable history access can simulate a Universal Turing Machine with at most logarithmic overhead in space and time complexity \cite{boyle2024memory,liskiewicz1994complexity}.
\end{theorem}

\begin{proof}
We proceed in three steps, following established frameworks for space-time tradeoffs \cite{swamy1983space,hu2014computational}:

\vspace{0.5em}
\noindent\underline{First}, we show that $S$ can implement the basic operations of a UTM. Let $M$ be a UTM with state set $Q$, tape alphabet $\Gamma$, and transition function $\delta$. We construct a simulation in $S$ as follows:

\vspace{0.5em}
\noindent\textbf{State Encoding:} Each configuration of $M$ is encoded as a tuple $s = (q, p, a, t)$ where: $q \in Q$ is the current machine state, $p \in \mathbb{N}$ is the head position, $a \in \Gamma$ is the symbol under the head, and $t \in \mathbb{N}$ is the step counter.
This encoding ensures efficient state validation and access \cite{boyle2024memory,hu2014computational}.

\vspace{0.5em}
\noindent\textbf{Tape Simulation:} For each position $p$ visited by $M$, we maintain a history entry $h_p = (p, a_p, t_p)$ where $a_p \in \Gamma$ is the symbol written at position $p$ and $t_p$ is the time step when this symbol was written.
This structure enables logarithmic-time access to tape contents \cite{swamy1983space,liskiewicz1994complexity}.

\vspace{0.5em}
\noindent\underline{Second}, we prove that these operations preserve computational state correctly through the following invariants:

\begin{lemma}[State Coherence]
At each step $t$, the simulated configuration $(q, p, a)$ exactly matches the configuration of $M$ after $t$ steps on the same input.
\end{lemma}

\begin{proof}
By induction on $t$:

\vspace{0.3em}
\noindent\textit{Base case} ($t=0$): The initial configuration matches by construction.

\vspace{0.3em}
\noindent\textit{Inductive step}: Assume the invariant holds for step $t$. 
For step $t+1$, $S$ reads current state $(q, p, a, t)$, computes $(q', a', d) = \delta(q, a)$, updates position $p' = p + d$, uses history access to find $a''$ at $p'$, and maintains new state $(q', p', a'', t+1)$.
This exactly mirrors $M$'s transition function, preserving the invariant.
\end{proof}

\begin{lemma}[History Consistency]
For any position $p$ and time $t$, the symbol recorded in history matches what would be on $M$'s tape at position $p$ at time $t$.
\end{lemma}

\begin{proof}
We maintain two invariants: each write operation creates a history entry with the current time step, and when reading position $p$, we retrieve the entry with maximum $t_p \leq t$.
This ensures we always see the most recent write to each position, exactly matching $M$'s tape contents.
\end{proof}

\vspace{0.5em}
\noindent\underline{Third, and finally}, we analyze the complexity bounds: The simulation incurs logarithmic overhead in both space ($O(\log t)$ bits for step counter and $O(\log n)$ bits for position encoding) and time ($O(\log t)$ for history access operations). These bounds are tight \cite{parzych2024memory,hhan2024new,boyle2024memory}, as demonstrated through recent impossibility results. Therefore, $S$ simulates $M$ with logarithmic overhead in both space and time \cite{savage1994space,vonkorff2019molecular,bennett1989time}.
\end{proof}

\begin{corollary}[Universality]
Any system with recursive state maintenance and reliable history access is Turing-complete.
\end{corollary}

\section{Fundamental constraints of parallel training}

The restriction of neural architectures to $\text{TC}_0$ complexity isn't merely an implementation artifact.
It emerges necessarily from the requirements of parallel training at scale \cite{merrill2023parallelism,peng2024limitations}.
To understand why, we must examine the fundamental independence assumptions required for parallel optimization \cite{shallue2019measuring}.

Consider a neural network trained on multiple devices \cite{zhao2024epha}.
For training to proceed efficiently in parallel, the computation graph must permit independent parameter updates across different portions of the network \cite{barrett2019analyzing}.
This requirement manifests differently across architectures but always imposes similar computational constraints.
In transformers, the attention mechanism enables parallel processing by treating each position independently modulo the attention weights.
In convolutional networks, the locality assumption enables parallel computation across the spatial dimension.
Even recurrent architectures, when unrolled for parallel training, must make independence assumptions between time steps \cite{dickson2023rnns}.

These independence assumptions limit the network's ability to implement sequential computation in a single forward pass \cite{wei2022chain}.
\cite{merrill2023parallelism} showed for transformers that computation requiring true sequential dependence cannot be implemented in a single forward pass through a parallel-trained network.
Their analysis extends to other architectures that rely on similar independence assumptions for parallel training \cite{stillman2023generative}.

The $\text{TC}_0$ limitation emerges from examining the backwards pass during training \cite{jung2020new}.
An architecture implementing arbitrary sequential computation in a single forward pass would require propagating gradients through this sequential computation, creating an inherently serial process that conflicts with parallel training \cite{zhu2024overcoming}.
The $\text{TC}_0$ bound thus follows directly from parallel trainability requirements.

\section{Computation in biological systems}

The central dogma of molecular biology reveals a fundamental truth about cellular computation: it operates entirely through parallel molecular interactions \cite{wang2023parallel,cai2024efficient,fu2023scgrn}.
Every aspect of information processing in the cell occurs through simultaneous reactions governed by concentration thresholds and binding affinities \cite{alberts2022molecular}.
Ion channels open and close in parallel across membranes based on voltage gradients, while G-protein coupled receptors simultaneously trigger cascades of second messengers \cite{alberts2022molecular}.
Even direct protein-protein interactions and mechanical signal transduction operate through vast networks of molecules simultaneously changing conformational states \cite{alberts2022molecular,berridge2014cell}.

This parallel processing isn't an implementation choice---it's fundamental to cellular metabolism \cite{cai2024efficient,hoel2020emergence}.
A cell cannot afford to serialize its basic information processing, whether through fast ion channels or slower biochemical cascades.
The need for metabolic efficiency forces parallel computation just as training efficiency forces parallelism in artificial neural networks \cite{barrett2019analyzing}.
This parallel architecture restricts cellular computation to $\text{TC}_0$ complexity: threshold functions operating on many inputs simultaneously, but no true sequential logic \cite{wang2023parallel}.

The brain transcends these parallel constraints through precise architectural design.
In the hippocampal-entorhinal system, dedicated ``time cells'' fire in precise sequences while ramping cells modulate their activity to provide temporal context \cite{quentin2019differential}.
The prefrontal cortex coordinates with the hippocampus to organize memories, while the parahippocampal region processes spatial and event details \cite{martini2015information}.
This system achieves ordered episodic memories not by making individual neurons sequential processors, but by maintaining state through multiple parallel components orchestrated in time.
Even here, the fundamental operations remain parallel---it is the sophisticated maintenance of state across specialized structures that enables sequential processing \cite{bruno2022epigenetic}.

Different biological systems have evolved various strategies for maintaining computational history \cite{espinosa2024molecular}.
At the cellular level, the cell cycle provides natural temporal boundaries for state maintenance.
Developmental biology shows how organisms maintain state across multiple timescales, from rapid cellular signaling to long-term morphological changes.
Neural systems implement particularly sophisticated memory structures that preserve both state and temporal relationships.

This principle appears repeatedly in biological systems \cite{fu2024memory}.
From immune memory to developmental patterning, organisms achieve complex computation not by overcoming the parallel nature of cellular processing, but by building additional layers of organization above it.
These solutions all share a common theme: they enable sequential computation through sophisticated mechanisms for maintaining and accessing computational state, rather than by changing the fundamental parallel nature of their constituent cells.

Recent experimental work confirms these computational bounds.
The MAP kinase pathway operates entirely through parallel protein modifications and threshold-based state changes \cite{alberts2022molecular}.
Even apparently sequential processes like the cell cycle are implemented through parallel molecular networks with threshold-based transitions rather than true sequential computation.

Organisms transcend these limitations through an array of specialized structures and multicellular organization \cite{espinosa2024molecular}.
At the cellular level, neural systems achieve sequential computation through synaptic modifications that maintain state across time \cite{fu2024memory}, while the immune system maintains computational history through specialized memory cells \cite{niu2022computational}.
But memory structures in biology extend far beyond these classical examples.

Developmental biology provides striking examples of memory-enabled computation.
The apical meristem in plants maintains positional information and developmental state through complex molecular networks, enabling precise control of phyllotaxis (leaf arrangement) and organ formation \cite{lovkvist2021using}.
This spatial memory system allows plants to maintain consistent developmental patterns despite environmental perturbations.
Similarly, the anterior-posterior axis and segmentation patterns in animal embryos emerge through maintained morphogen gradients and sequential state updates \cite{pastor2020computation}.
These patterns demonstrate remarkable robustness, with the ability to regenerate proper proportions even after significant tissue removal or reorganization \cite{lobo2012towards}.

Even seemingly simple organisms like slime molds achieve complex computation through physical memory structures in their multicellular aggregates.
These organisms can solve optimization problems and maintain spatial memories of their environment through modifications to their extracellular matrix \cite{hoel2020emergence}.
This demonstrates how memory-enabled computation can emerge from basic biological building blocks without requiring specialized neural tissue.

Recent work in synthetic biology demonstrates attempts to implement recording systems using molecular mechanisms.
While natural systems like CRISPR arrays suggest potential for sequential molecular recording, most current approaches require artificial constructs.
Researchers have explored various strategies: using engineered CRISPR systems to accumulate genomic modifications \cite{sheth2017multiplex}, developing sequential editing frameworks \cite{choi2022time}, and creating synthetic mutation-based storage systems \cite{sadremomtaz2023digital}.
These efforts highlight both the challenge and potential of implementing reliable state maintenance in molecular systems, though their artificial nature limits direct comparison to evolved biological memory mechanisms.

These memory mechanisms operate across multiple scales, from molecular to organismal.
At the cellular level, epigenetic modifications and protein-based switches maintain cell identity.
At the tissue level, developmental patterns are maintained through both cellular memory and tissue organization.
At the organism level, the genome itself acts as a form of evolutionary memory, encoding solutions to computational problems faced by ancestors.
These diverse solutions share a common principle: they enable complex computation not through more sophisticated basic units, but through maintaining and accessing computational state via specialized structures.
This mirrors how artificial systems overcome parallel processing limitations through recursive state maintenance rather than more complex basic units.

\section{Practical implications}

The lens of recursive state maintenance informs the design and use of AI systems \cite{dickson2024trust,ahn2024recursive,openai2024o1}.
Parallel processing limitations represent fundamental constraints that shape how these systems operate to achieve complex reasoning \cite{merrill2023parallelism}, with recent evidence showing both the power and limitations of recursive reasoning approaches \cite{liu2024mind}.

Traditional approaches to improving AI capabilities have focused on scaling parallel processing power---larger models, more sophisticated attention mechanisms, deeper networks \cite{shallue2019measuring}.
Our analysis suggests this approach, while useful for pattern matching capabilities, cannot address the fundamental limitations of sequential reasoning \cite{peng2024limitations}.
Recent empirical evidence from the OpenAI o1 system demonstrates that chain-of-thought reasoning provides new opportunities for safety monitoring and validation of our theoretical framework \cite{openai2024o1}.
However, just as biological systems don't solve sequential computation by making cells more complex \cite{wang2023parallel}, we won't solve it by making transformer layers more sophisticated \cite{zhao2024epha}.

Instead, architectural innovation should focus on robust mechanisms for state maintenance and recursive processing \cite{jung2020new}.
This might involve memory systems that maintain coherent state across multiple processing steps \cite{zhu2024overcoming}.
Recent research has identified specific conditions where chain-of-thought reasoning can actually reduce performance, particularly in tasks where the underlying computation requires implicit pattern recognition rather than explicit reasoning \cite{liu2024mind}.
This aligns with our framework's prediction that memory-based recursive computation is most effective when the task requires true sequential dependence, rather than parallel pattern matching.
State verification mechanisms that ensure consistency across recursive processing steps, similar to how biological systems maintain state coherence through specialized cellular structures \cite{espinosa2024molecular}, become crucial for maintaining reliable computation.

The implications for system interaction are equally profound and immediately practical \cite{wei2022chain}.
When interacting with language models, we're not dealing with a system that "thinks" in a single forward pass.
Instead, we're engaging with a computational process that must build up complex reasoning through recursive state refinement \cite{dickson2024trust}.
This leads to testable hypotheses about when recursive reasoning will help or hinder performance: (1) tasks requiring true sequential dependence will benefit from chain-of-thought reasoning, while (2) tasks dominated by parallel pattern recognition may actually suffer from forced sequential processing \cite{liu2024mind}.

This explains why certain interaction patterns prove particularly effective.
Chain-of-thought prompting works not because it teaches the model to reason, but because it provides a framework for recursive state maintenance \cite{wei2022chain}.
The model isn't learning new capabilities during the interaction---it's being given a structure for maintaining computational state across multiple steps \cite{ahn2024recursive}.

The effectiveness of these approaches can be understood through the lens of computational history access \cite{fu2024memory}.
Chain-of-thought prompting works not by changing the underlying computation, but by providing clear temporal structure for maintaining and accessing computational state \cite{wei2022chain}.
Similarly, successful memory architectures in AI systems can be viewed as different strategies for implementing reliable history access with clear temporal boundaries \cite{yang2013survey}.

The success of large language models, particularly autoregressive models \cite{schuurmans2024autoregressive}, demonstrates how systems can achieve complex computation by learning transition functions from observed computational processes.
These models are trained on vast collections of text that represent traces of human computation---written explanations, logical arguments, mathematical derivations, and other records of human information processing \cite{brown2020language}.
This training enables them to internalize the basic transition functions that humans apply when processing information \cite{wei2022chain}.

When presented with prompts containing examples, LLMs can effectively apply learned patterns to break down complex problems into steps, implementing a form of recursive reasoning \cite{wei2022chain}.
This reasoning occurs without weight updates, suggesting the models have internalized generalizable computational patterns from their training data.
The success of techniques like chain-of-thought prompting demonstrates that these models can effectively replicate human-like problem-solving approaches when given appropriate frameworks for maintaining computational state \cite{wei2022emergent}.

This perspective illuminates why techniques like chain-of-thought prompting prove effective: they provide a framework for applying learned human computational patterns recursively while maintaining state across steps \cite{wei2022chain}.
The success of these methods depends not on teaching models new reasoning capabilities, but on structuring computation to leverage already-learned transition functions in a way that enables reliable state maintenance and access.

\section{Conclusion}

Our analysis highlights a critical insight for artificial intelligence.
While significant progress has been made in training transition functions through exposure to human computational traces in text, we may be approaching fundamental limits of this approach alone.
Current language models demonstrate this.
They have effectively learned to replicate human-like information processing patterns, yet their capabilities show diminishing returns from scale.
The key contribution of this work is to remind us that universal computation requires not just sophisticated transition functions, but also robust memory mechanisms for maintaining and accessing computational state.

This perspective suggests a shift in focus for AI development.
Rather than solely pursuing more powerful pattern matching through larger models, progress may require equal attention to the memory and state maintenance mechanisms that enable recursive computation.
By returning to these fundamental requirements of computation, we gain insight into both the current limitations and future directions of artificial intelligence, while deepening our understanding of computation across both artificial and biological systems.

\begingroup
\footnotesize
\bibliographystyle{plain}
\bibliography{refs}
\endgroup

\end{document}
