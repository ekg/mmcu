\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{fontspec}
\setsansfont{Liberation Sans}
\geometry{
    a4paper,
    margin=2.5cm,
    includehead,
    includefoot
}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=black]{hyperref}
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{bbm}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\title{Memory makes computation universal, remember?}
\author{Erik Garrison\\
  \texttt{egarris5@uthsc.edu}\\[1ex]
  }
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Memory makes universal computation possible through two fundamental capabilities: recursive state maintenance and reliable history access.
This minimality becomes especially clear when examining parallel systems.
While parallel architectures like neural networks and biological cells are inherently limited to threshold circuits---they achieve universal computation through state maintenance across iterations.
We prove these two capabilities are sufficient for universal computation and demonstrate how this manifests in biological systems through specialized cellular structures and in artificial neural networks through techniques like chain-of-thought reasoning.
We argue that language models achieve complex sequential reasoning by learning to replicate the fundamental computational patterns embedded in human language - through massive exposure to text containing human reasoning traces, these models internalize the basic transition functions that characterize human thought expressed in language.
This theoretical framework unifies our understanding of computation across minds, machines, and living systems, reminding us that humanity's computational capabilities have evolved in step with our technical ability to remember through oral traditions, writing, and now computing.
\end{abstract}

\section{Introduction}
Memory is not just a feature of computational systemsâ€”it is the key capability that enables universal computation~\cite{turing1936computable}.
Even systems with very basic state transitions can achieve universal computation when equipped with memory~\cite{merrill2023parallelism,peng2024limitations}.
This principle is demonstrated by remarkably minimal universal systems like Rule 110 cellular automata~\cite{cook2004universality} and the universality of the mov+jmp instruction set~\cite{savage1994space}.
We show how this fundamental insight manifests in computational systems ranging from neural networks to biological cells~\cite{wang2023parallel}, where simple parallel operations combined with state maintenance enable complex computation~\cite{swamy1983space,bisaz2024memory}.

Physical reality presents two fundamentally different paths to computation: the precise control of electromagnetic flows in silicon ("lightning in a rock") versus the messy parallel molecular interactions of biological systems.
While we can engineer silicon chips to perform computation by precisely controlling electromagnetic flows through crystalline structures, biological systems had to solve computational problems through inherently "blobby, wet" parallel molecular mechanisms.
This parallel architecture - where computation emerges from countless simultaneous molecular interactions - fundamentally constrains such systems to threshold circuits.
Neural networks optimize for parallel processing to enable efficient training across multiple devices \cite{merrill2023parallelism,merrill2024}, while cells operate through vast networks of simultaneous molecular interactions, with each molecule functioning as an independent parallel process \cite{fu2023scgrn}.
Yet through sophisticated mechanisms that maintain state across multiple steps---like chain-of-thought reasoning in language models \cite{wei2022chain,qiu2024ask} and molecular memory in cells \cite{hoel2020emergence}---these systems achieve complex sequential computation.
The transformer architecture demonstrates how parallel processing can be combined with state maintenance to achieve complex computation.
Through its attention mechanism, it efficiently processes information in parallel while maintaining computational state across multiple steps \cite{merrill2024}.
The power of this approach scales with memory capacity, as proven by recent theoretical work showing how computational capabilities increase with the number of maintained intermediate states \cite{merrill2024}.
From neural synapses to developmental patterns and genomic evolution, biological systems demonstrate how diverse memory structures enable complex information processing \cite{burrill2010making,espinosa2024molecular}.
In artificial systems, techniques like chain-of-thought prompting provide frameworks for memory-based recursive computation \cite{wei2022chain,dickson2024trust,ahn2024recursive}.
In both domains, universal computation emerges not through more complex computational units, but through memory mechanisms that maintain and access computational state \cite{schuurmans2024autoregressive}.

We demonstrate how two basic capabilities---recursive state maintenance and reliable history access---are sufficient for universal computation \cite{bennett1989time,boyle2024memory}.
We first establish this formally through a constructive proof, grounding our subsequent analysis in computational theory.
We then examine how parallel processing limitations manifest in both artificial neural networks and biological systems, showing how these systems achieve complex computation through memory rather than sophisticated processing units.
Finally, we explore the practical implications for artificial intelligence development, particularly in the context of large language models and recursive reasoning.
This analysis provides a unified perspective on computation across domains while suggesting new directions for AI architecture development focused on robust state maintenance mechanisms.

\section{Basic requirements and construction}

A system has recursive state processing if it can read its current state $s$, generate an update function $f(s)$ that produces the next state, and maintain the new state $f(s)$ for subsequent processing \cite{manuri2019state}.
This state maintenance must be robust against errors and degradation \cite{yang2013survey}.

A system has reliable history access if it can: (1) reference any previous state $s_i$ from its computation history without error \cite{fu2024memory}, (2) distinguish between different states in its history unambiguously, (3) maintain and determine the correct temporal order of states \cite{berridge2014cell,pastor2020computation}, establishing clear boundaries between computational periods, and (4) guarantee the integrity of stored states \cite{lovkvist2021using}.
The system need not maintain its entire history in active memory, but when it accesses stored states, it must do so reliably and correctly.

To illustrate how memory transforms simple operations into universal computation, consider a basic threshold unit that checks if a number is greater than zero.
Without memory, this unit can only output yes/no signals---a trivial, static operation.
However, with memory to store previous results, this same unit becomes capable of counting: starting from zero, it can repeatedly increment its input and maintain the running total, transforming a simple parallel threshold operation into a sequential counter.
This counter then serves as a fundamental building block for more complex operations, enabling program sequencing and even Turing machine simulation.

This requirement for reliable history access naturally creates temporal structure in computation.
Different systems implement this in various ways---neural networks through attention windows and forward passes \cite{martini2015information,quentin2019differential}, cells through cell cycle phases and epigenetic mechanisms \cite{bruno2022epigenetic}, and organisms through developmental stages.
In each case, the system must maintain clear temporal boundaries to ensure reliable access to its computational history.

These capabilities enable universal computation through a straightforward construction \cite{deutsch1995universality,bennett1989time}.
Given a Universal Turing Machine $U$, we implement it as follows: The state $s = (q, p, a)$ encodes the current machine state $q$, the position $p$ of the tape head, and the symbol $a$ under the head.
At each step, the system processes current state $s$ to determine $(q', a', d) = \delta(q, a)$, where $q'$ is the next machine state, $a'$ is the symbol to write, and $d$ is the head movement.
It uses history access to reconstruct tape contents as needed and maintains the new state for the next step.

\section{Completeness of the construction}

The elegance of these requirements---recursive state maintenance and reliable history access---is demonstrated by a remarkably simple proof of their sufficiency for universal computation.
This proof provides the mathematical foundation for our broader discussion of computation across artificial and biological systems.
Its simplicity reinforces our central argument: universal computation emerges not from complex processing units, but from basic capabilities for maintaining and accessing computational state.

\vspace{1em}

\begin{theorem}[Completeness]
Any system $S$ with recursive state maintenance and reliable history access can simulate a Universal Turing Machine with at most logarithmic overhead in space and time complexity \cite{boyle2024memory,liskiewicz1994complexity}.
\end{theorem}

\begin{proof}
We proceed in three steps, following established frameworks for space-time tradeoffs \cite{swamy1983space,hu2014computational}:

\vspace{0.5em}
\noindent\underline{First}, we show that $S$ can implement the basic operations of a UTM. Let $M$ be a UTM with state set $Q$, tape alphabet $\Gamma$, and transition function $\delta$. We construct a simulation in $S$ as follows:

\vspace{0.5em}
\noindent\textbf{State Encoding:} Each configuration of $M$ is encoded as a tuple $s = (q, p, a, t)$ where: $q \in Q$ is the current machine state, $p \in \mathbb{N}$ is the head position, $a \in \Gamma$ is the symbol under the head, and $t \in \mathbb{N}$ is the step counter.
This encoding ensures efficient state validation and access \cite{boyle2024memory,hu2014computational}.

\vspace{0.5em}
\noindent\textbf{Tape Simulation:} For each position $p$ visited by $M$, we maintain a history entry $h_p = (p, a_p, t_p)$ where $a_p \in \Gamma$ is the symbol written at position $p$ and $t_p$ is the time step when this symbol was written.
This structure enables logarithmic-time access to tape contents \cite{swamy1983space,liskiewicz1994complexity}.

\vspace{0.5em}
\noindent\underline{Second}, we prove that these operations preserve computational state correctly through the following invariants:

\begin{lemma}[State Coherence]
At each step $t$, the simulated configuration $(q, p, a)$ exactly matches the configuration of $M$ after $t$ steps on the same input.
\end{lemma}

\begin{proof}
By induction on $t$:

\vspace{0.3em}
\noindent\textit{Base case} ($t=0$): The initial configuration matches by construction.

\vspace{0.3em}
\noindent\textit{Inductive step}: Assume the invariant holds for step $t$. 
For step $t+1$, $S$ reads current state $(q, p, a, t)$, computes $(q', a', d) = \delta(q, a)$, updates position $p' = p + d$, uses history access to find $a''$ at $p'$, and maintains new state $(q', p', a'', t+1)$.
This exactly mirrors $M$'s transition function, preserving the invariant.
\end{proof}

\begin{lemma}[History Consistency]
For any position $p$ and time $t$, the symbol recorded in history matches what would be on $M$'s tape at position $p$ at time $t$.
\end{lemma}

\begin{proof}
We maintain two invariants: each write operation creates a history entry with the current time step, and when reading position $p$, we retrieve the entry with maximum $t_p \leq t$.
This ensures we always see the most recent write to each position, exactly matching $M$'s tape contents.
\end{proof}

\vspace{0.5em}
\noindent\underline{Third, and finally}, we analyze the complexity bounds: The simulation incurs logarithmic overhead in both space ($O(\log t)$ bits for step counter and $O(\log n)$ bits for position encoding) and time ($O(\log t)$ for history access operations). These bounds are tight \cite{parzych2024memory,hhan2024new,boyle2024memory}, as demonstrated through recent impossibility results. Therefore, $S$ simulates $M$ with logarithmic overhead in both space and time \cite{savage1994space,vonkorff2019molecular,bennett1989time}.
\end{proof}

\begin{corollary}[Universality]
Any system with recursive state maintenance and reliable history access is Turing-complete.
\end{corollary}

\section{Fundamental constraints of parallel training}

The restriction of neural architectures to $\text{TC}_0$ complexity isn't merely an implementation artifact---it represents a fundamental computational barrier proven by recent theoretical work~\cite{merrill2023parallelism,peng2024limitations}.
This limitation emerges necessarily from the requirements of parallel training at scale, with quantitative bounds now established on both the computational power and limitations of these architectures.
To understand why, we must examine the fundamental independence assumptions required for parallel optimization~\cite{shallue2019measuring}.

Recent work by Merrill \& Sabharwal (2024) proves that transformer architectures gain computational power in precise, quantifiable steps through state maintenance mechanisms.
Their analysis shows that each additional processing step increases computational capability in a measurable way, but only when proper state maintenance is preserved across steps.
These results directly support our framework by demonstrating how memory mechanisms, not architectural complexity, determine computational power.

Consider a neural network trained on multiple devices \cite{zhao2024epha}.
For training to proceed efficiently in parallel, the computation graph must permit independent parameter updates across different portions of the network \cite{barrett2019analyzing}.
This requirement manifests differently across architectures but always imposes similar computational constraints.
In transformers, the attention mechanism enables parallel processing by treating each position independently modulo the attention weights.
In convolutional networks, the locality assumption enables parallel computation across the spatial dimension.
Even recurrent architectures, when unrolled for parallel training, must make independence assumptions between time steps \cite{dickson2023rnns}.

These independence assumptions limit the network's ability to implement sequential computation in a single forward pass \cite{wei2022chain}. A potential objection here is that neural networks might achieve sequential computation through mechanisms other than explicit state maintenance---for instance, through learned representations that implicitly encode sequential dependencies. However, theoretical work by \cite{merrill2023parallelism} proves that such implicit encoding cannot circumvent the fundamental limitations imposed by parallel training requirements.
\cite{merrill2023parallelism} showed for transformers that computation requiring true sequential dependence cannot be implemented in a single forward pass through a parallel-trained network.
Their analysis extends to other architectures that rely on similar independence assumptions for parallel training \cite{stillman2023generative}.

The $\text{TC}_0$ limitation emerges from examining the backwards pass during training \cite{jung2020new}.
An architecture implementing arbitrary sequential computation in a single forward pass would require propagating gradients through this sequential computation, creating an inherently serial process that conflicts with parallel training \cite{zhu2024overcoming}.
The $\text{TC}_0$ bound thus follows directly from parallel trainability requirements.

\section{Computation in biological systems}

The central dogma of molecular biology reveals how cells solve computation through inherently parallel mechanisms \cite{wang2023parallel,cai2024efficient,fu2023scgrn}.
Unable to engineer precise electromagnetic flows like silicon systems, cells must process information through vast networks of simultaneous molecular interactions.
Every aspect of cellular computation occurs through parallel reactions governed by concentration thresholds and binding affinities \cite{alberts2022molecular}.
Ion channels open and close in parallel across membranes based on voltage gradients, while G-protein coupled receptors simultaneously trigger cascades of second messengers \cite{alberts2022molecular}.
Even direct protein-protein interactions and mechanical signal transduction operate through networks of molecules simultaneously changing conformational states \cite{alberts2022molecular,berridge2014cell}.

This parallel processing isn't an implementation choice---it's fundamental to cellular metabolism \cite{cai2024efficient,hoel2020emergence}.
A cell cannot afford to serialize its basic information processing, whether through fast ion channels or slower biochemical cascades.
The need for metabolic efficiency forces parallel computation just as training efficiency forces parallelism in artificial neural networks \cite{barrett2019analyzing}.
This parallel architecture restricts cellular computation to $\text{TC}_0$ complexity: threshold functions operating on many inputs simultaneously, but no true sequential logic \cite{wang2023parallel}.

The brain transcends these parallel constraints through precise architectural design.
In the hippocampal-entorhinal system, dedicated ``time cells'' fire in precise sequences while ramping cells modulate their activity to provide temporal context \cite{quentin2019differential}.
The prefrontal cortex coordinates with the hippocampus to organize memories, while the parahippocampal region processes spatial and event details \cite{martini2015information}.
This system achieves ordered episodic memories not by making individual neurons sequential processors, but by maintaining state through multiple parallel components orchestrated in time.
Even here, the fundamental operations remain parallel---it is the sophisticated maintenance of state across specialized structures that enables sequential processing \cite{bruno2022epigenetic}.

Different biological systems have evolved various strategies for maintaining computational history \cite{espinosa2024molecular}.
At the cellular level, the cell cycle provides natural temporal boundaries for state maintenance.
Developmental biology shows how organisms maintain state across multiple timescales, from rapid cellular signaling to long-term morphological changes.
Neural systems implement particularly sophisticated memory structures that preserve both state and temporal relationships.

This principle appears repeatedly in biological systems \cite{fu2024memory}.
From immune memory to developmental patterning, organisms achieve complex computation not by overcoming the parallel nature of cellular processing, but by building additional layers of organization above it.
These solutions all share a common theme: they enable sequential computation through sophisticated mechanisms for maintaining and accessing computational state, rather than by changing the fundamental parallel nature of their constituent cells.

Recent experimental work confirms these computational bounds.
The MAP kinase pathway operates entirely through parallel protein modifications and threshold-based state changes \cite{alberts2022molecular}.
Even apparently sequential processes like the cell cycle are implemented through parallel molecular networks with threshold-based transitions rather than true sequential computation.

Organisms transcend these limitations through an array of specialized structures and multicellular organization \cite{espinosa2024molecular}.
At the cellular level, neural systems achieve sequential computation through synaptic modifications that maintain state across time \cite{fu2024memory}, while the immune system maintains computational history through specialized memory cells \cite{niu2022computational}.
But memory structures in biology extend far beyond these classical examples.

Developmental biology provides striking examples of memory-enabled computation.
The apical meristem in plants maintains positional information and developmental state through complex molecular networks, enabling precise control of phyllotaxis (leaf arrangement) and organ formation \cite{lovkvist2021using}.
This spatial memory system allows plants to maintain consistent developmental patterns despite environmental perturbations.
Similarly, the anterior-posterior axis and segmentation patterns in animal embryos emerge through maintained morphogen gradients and sequential state updates \cite{pastor2020computation}.
These patterns demonstrate remarkable robustness, with the ability to regenerate proper proportions even after significant tissue removal or reorganization \cite{lobo2012towards}.

Even seemingly simple organisms like slime molds achieve complex computation through physical memory structures in their multicellular aggregates.
These organisms can solve optimization problems and maintain spatial memories of their environment through modifications to their extracellular matrix \cite{hoel2020emergence}.
This demonstrates how memory-enabled computation can emerge from basic biological building blocks without requiring specialized neural tissue.

The CRISPR-Cas system provides a striking example of evolution discovering the simplest possible tape-based solution for maintaining computational state.
When life needed temporal logging, it created perhaps the most minimal possible sequential memory structure: CRISPR arrays implement a remarkably efficient biological tape where new viral sequences are inserted at one end while maintaining a chronological record of past infections \cite{sheth2017multiplex}.
This system demonstrates how fundamental computational needs---in this case, maintaining an adaptive immune memory---drive the evolution of fundamental solutions that mirror theoretical minimal systems.
The CRISPR locus acts as a write-once tape, with the Cas proteins implementing the read/write mechanisms through precise DNA manipulation \cite{choi2022time}.

What makes CRISPR particularly illuminating is how it integrates different scales of biological memory.
The DNA-based CRISPR array provides stable, long-term storage of viral sequences, while protein-based Cas complexes implement the active computational machinery \cite{sadremomtaz2023digital}.
This mirrors our theoretical framework: the system separates state maintenance (DNA array) from state processing (Cas proteins), achieving universal computation through their interaction.
The fact that evolution converged on this tape-based architecture suggests it represents a fundamental solution to the computational challenge of adaptive immunity.

Recent work in synthetic biology builds on these principles, implementing recording systems that combine DNA-based storage with protein-based processing.
Researchers have developed engineered CRISPR systems that accumulate genomic modifications \cite{sheth2017multiplex}, sequential editing frameworks \cite{choi2022time}, and synthetic mutation-based storage systems \cite{sadremomtaz2023digital}.
These efforts demonstrate how understanding biological memory mechanisms can inform the design of synthetic computational systems.

These memory mechanisms operate across multiple scales, from molecular to organismal.
At the cellular level, epigenetic modifications and protein-based switches maintain cell identity.
At the tissue level, developmental patterns are maintained through both cellular memory and tissue organization.
At the organism level, the genome itself acts as a form of evolutionary memory, encoding solutions to computational problems faced by ancestors.
These diverse solutions share a common principle: they enable complex computation not through more complex basic operations, but through maintaining and accessing computational state via specialized structures.
This mirrors how artificial systems overcome parallel processing limitations through recursive state maintenance rather than more complex basic units.

\section{Practical implications}

The lens of recursive state maintenance informs the design and use of AI systems \cite{dickson2024trust,ahn2024recursive,openai2024o1}.
Parallel processing limitations represent fundamental constraints that shape how these systems operate to achieve complex reasoning \cite{merrill2023parallelism}, with recent evidence showing both the power and limitations of recursive reasoning approaches \cite{liu2024mind}.

Traditional approaches to improving AI capabilities have focused on scaling parallel processing power---larger models, more sophisticated attention mechanisms, deeper networks \cite{shallue2019measuring}.
Our analysis suggests this approach, while useful for pattern matching capabilities, cannot address the fundamental limitations of sequential reasoning \cite{peng2024limitations}.
Recent empirical evidence from the OpenAI o1 system demonstrates that chain-of-thought reasoning provides new opportunities for safety monitoring and validation of our theoretical framework \cite{openai2024o1}.
However, just as biological systems don't solve sequential computation by making cells more complex \cite{wang2023parallel}, we won't solve it by making transformer layers more sophisticated \cite{zhao2024epha}.

Instead, architectural innovation should focus on robust mechanisms for state maintenance and recursive processing \cite{jung2020new}.
This might involve memory systems that maintain coherent state across multiple processing steps \cite{zhu2024overcoming}.
Recent research has identified specific conditions where chain-of-thought reasoning can actually reduce performance, particularly in tasks where the underlying computation requires implicit pattern recognition rather than explicit reasoning \cite{liu2024mind}.
This aligns with our framework's prediction that memory-based recursive computation is most effective when the task requires true sequential dependence, rather than parallel pattern matching.
State verification mechanisms that ensure consistency across recursive processing steps, similar to how biological systems maintain state coherence through specialized cellular structures \cite{espinosa2024molecular}, become crucial for maintaining reliable computation.

The history of the ARC Prize reveals both the limitations of traditional neural approaches and the power of memory-based computation. In the first Kaggle competition in 2020, no deep learning-based approach scored above 1\%, and the original GPT-3 model scored 0\% on the public evaluation via direct prompting. Even modern LLMs with sophisticated attention mechanisms perform poorly when used in a static way - GPT-4o achieves only 5\%, Gemini 1.5 reaches 4.5\%, and Claude 3.5 Sonnet manages 14\% on pass@1 evaluation \cite{chollet2024arc}. However, the introduction of test-time training dramatically improved performance, with top approaches in the 2024 competition achieving 55.5\% accuracy through state maintenance mechanisms \cite{chollet2024arc}.

The implications for system interaction reveal how pattern matching and sequential reasoning complement each other \cite{wei2022chain}.
Pattern matching operates through parallel processing of input features, enabling rapid recognition within the constraints of threshold computations---this allows efficient processing of short sequences through direct feature detection and motif recognition.
The parallel nature of this processing enables simultaneous evaluation of multiple features against learned templates, while maintaining clear computational bounds on what can be achieved in a single pass.
Sequential reasoning extends these capabilities by maintaining and updating state across multiple steps, enabling complex logical deductions through recursive composition of simpler pattern-matching operations \cite{dickson2024trust}.
The transformer architecture exemplifies our theoretical framework by combining parallel processing with sophisticated state maintenance.
Its attention mechanism enables efficient parallel feature detection across inputs, while its layer-wise processing provides natural boundaries for maintaining computational state.
This architecture respects the parallel constraints we identified while implementing reliable history access through its attention patterns.
The result is a system that excels at parallel pattern matching but requires explicit state maintenance through techniques like chain-of-thought prompting to achieve sequential reasoning - exactly as our framework predicts.
This explains the empirically observed pattern where transformers excel at immediate pattern recognition but require guided state maintenance for complex logical reasoning \cite{wei2022chain,liu2024mind}. Recent work by Liu et al. demonstrates that forcing chain-of-thought reasoning can actually degrade performance on tasks better suited to implicit pattern recognition, such as artificial grammar learning and face matching tasks \cite{liu2024mind}. This mirrors human cognition, where explicit verbal reasoning can interfere with tasks that rely on implicit pattern recognition abilities.

The relationship between compression and state maintenance provides another key insight.
Language models achieve remarkable compression of human knowledge through their training process, essentially learning a distributed representation of common patterns in text.
However, this compression fundamentally differs from state maintenance, compression captures static patterns, while state maintenance enables dynamic computation through recursive updates \cite{dickson2024trust}.
This explains why models can recognize complex patterns instantly but require explicit state maintenance through prompting to perform step-by-step reasoning.

The handling of short versus long sequences further illuminates these principles.
Short sequences can often be processed through pure pattern matching within a single forward pass, leveraging the model's compressed knowledge.
Longer sequences requiring true sequential reasoning, however, demand explicit state maintenance across multiple steps \cite{wei2022chain}.
This mirrors how humans process information: immediate pattern recognition for familiar short sequences, versus deliberate step-by-step reasoning for complex logical deductions.

The key insight is that language models achieve sequential reasoning by learning to replicate fundamental computational patterns embedded in human language.
Through massive exposure to text containing human reasoning traces---explanations, proofs, arguments, and other forms of structured thought---these models internalize the basic transition functions that characterize human thought expressed in language.
When provided with sufficient context (state), they can then apply these learned patterns to perform sequential reasoning, even though their underlying architecture remains parallel.
This explains why techniques like chain-of-thought prompting are so effective: they provide a framework for the model to apply its learned computational patterns in a step-by-step manner, maintaining state through the prompt context.
This leads to testable hypotheses about when recursive reasoning will help or hinder performance: (1) tasks requiring true sequential dependence will benefit from chain-of-thought reasoning, while (2) tasks dominated by parallel pattern recognition may actually suffer from forced sequential processing \cite{liu2024mind}.

Some researchers argue that our framework oversimplifies the relationship between memory and computation, particularly in complex systems like language models. They contend that emergent capabilities might arise from architectural features beyond simple state maintenance, pointing to phenomena like in-context learning that seem to transcend simple memory mechanisms. While these objections raise important points about the complexity of modern AI systems, they ultimately reinforce rather than refute our core thesis. The very mechanisms cited as alternatives to memory-based computation---attention, in-context learning, emergent representations---all depend fundamentally on maintaining and accessing computational state.

This explains why certain interaction patterns prove particularly effective.
Chain-of-thought prompting makes language models universal computers, even though they're limited to threshold computations (TC0) in each forward pass \cite{wei2022chain}.
This isn't theoretical---we can prove it.
Each prompt step provides the state maintenance needed for universal computation, while the model's learned patterns provide the transition functions.
The model doesn't learn new capabilities during prompting---it's using its pre-trained knowledge within a computational framework that enables universal computation through state maintenance \cite{ahn2024recursive}.

The power of this approach comes from computational history access \cite{fu2024memory}.
Each step in the chain builds on previous results while maintaining clear temporal structure \cite{wei2022chain}.
Similarly, successful memory architectures in AI systems can be viewed as different strategies for implementing reliable history access with clear temporal boundaries \cite{yang2013survey}.

The remarkable leap in language model capabilities emerged from massive overtraining on an unprecedented coverage of human knowledge \cite{schuurmans2024autoregressive}.
This represents a form of transfer learning where human computational patterns are distilled into the model's parameters.
This extensive exposure enabled these systems to learn and internalize the fundamental transition functions that humans use with language.
When provided with sufficient context (state), these models can achieve human-level performance precisely because they have learned to replicate human computational patterns through exposure to vast collections of text---our recorded explanations, arguments, derivations, and other traces of human thought \cite{brown2020language,wei2022chain}.

When presented with prompts containing examples, LLMs can effectively apply learned patterns to break down complex problems into steps, implementing a form of recursive reasoning \cite{wei2022chain}.
This reasoning occurs without weight updates, suggesting the models have internalized generalizable computational patterns from their training data.
The success of techniques like chain-of-thought prompting demonstrates that these models can effectively replicate human-like problem-solving approaches when given appropriate frameworks for maintaining computational state \cite{wei2022emergent}.

This perspective illuminates why techniques like chain-of-thought prompting prove effective: they provide a framework for applying learned human computational patterns recursively while maintaining state across steps \cite{wei2022chain}.
The success of these methods depends not on teaching models new reasoning capabilities, but on structuring computation to leverage already-learned transition functions in a way that enables reliable state maintenance and access.

\section{But\ldots}

One might raise several substantive challenges to our memory-centric framework.
First, modern transformer architectures achieve their capabilities through sophisticated attention mechanisms that seem to transcend simple state maintenance~\cite{merrill2023parallelism}.
Second, neural approaches appear to lack the explicit symbolic manipulation that characterizes human mathematical reasoning~\cite{wei2022chain}.
Third, biological systems exhibit computational capabilities that emerge from complex network dynamics rather than explicit memory mechanisms~\cite{wang2023parallel}.
Recent empirical results, however, provide strong responses to each objection.
Merrill \& Sabharwal~\cite{merrill2024} prove that transformers gain computational power in precise, quantifiable steps through state maintenance mechanisms, while recent work demonstrates that neural approaches with proper state maintenance can match human performance on abstract reasoning tasks without explicit symbolic manipulation~\cite{qiu2024ask}.
In biological systems, seemingly complex network dynamics are increasingly understood as implementations of robust state maintenance, as shown by recent work on cellular memory circuits~\cite{espinosa2024molecular}.
These results strengthen rather than challenge our thesis about memory's fundamental role.

\section{Conclusion}

Our analysis highlights a critical insight about the recent advances in artificial intelligence.
The breakthrough in language model capabilities came not from architectural innovations, but from massive overtraining on an unprecedented coverage of human knowledge, enabling these systems to learn the human transition function itself.
When combined with sufficient context windows for state maintenance, this allows them to achieve human-level performance across many tasks.

The principle extends beyond AI.
From oral traditions to writing systems to modern computing, human civilization has advanced through transformations in its ability to maintain and access computational state.
Similarly, biological systems evolved from simple cellular memory to sophisticated neural architectures.
At each level, from individual cells to human culture, the ability to maintain and reliably access state determines computational capability.

This perspective suggests a shift in focus for AI development.
Rather than solely pursuing more powerful pattern matching through larger models, progress may require equal attention to the memory and state maintenance mechanisms that enable recursive computation.
By returning to these fundamental requirements, we can better understand computation across minds, machines, and living systems.

\begingroup
\footnotesize
\bibliographystyle{unsrt}
\bibliography{refs}
\endgroup

\end{document}
