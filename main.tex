\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{fontspec}
\setsansfont{Liberation Sans}
\geometry{
    a4paper,
    margin=2.5cm,
    includehead,
    includefoot
}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{bbm}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\title{Universal Computation Through Recursive State Maintenance\\in Living and Artificial Systems}
\author{Erik Garrison\\
  \texttt{egarris5@uthsc.edu}\\[1ex]
  }
\date{November 29, 2024}

\begin{document}
\maketitle

\begin{abstract}
While large language models have revolutionized AI, a fundamental aspect of their operation is often overlooked: they must think recursively to overcome their basic computational limitations. We prove that any system operating with history access and recursive state maintenance capabilities implements a Universal Turing Machine (UTM). This result is particularly significant given that parallel-trained neural networks and individual biological cells are limited to $\text{TC}_0$ complexity in single forward passes. Our analysis demonstrates how recursive reasoning with state maintenance transcends these limitations in both artificial and biological systems, while revealing that the logarithmic overhead in our complexity bounds stems from fundamental state encoding requirements.
\end{abstract}

\section{Introduction}
To achieve efficient training at scale, modern neural architectures employ various techniques that trade sequential computation for parallel efficiency. In transformers, this manifests through attention mechanisms. Other architectures use different approaches, from structured state spaces to various forms of gated updates. While these approaches are fundamentally different in their implementation, they share a common constraint: to enable parallel training, they must make assumptions about independence between computational channels. As shown rigorously for transformers by Merrill \& Sabharwal (2024), this leads to a fundamental limitation---restriction to $\text{TC}_0$ complexity in a single forward pass.

This limitation helps explain why language models, despite their impressive capabilities, sometimes struggle with basic sequential reasoning tasks that humans find trivial. The models aren't stupid---they're architecturally constrained by the requirements of parallel training. The same limitation appears in biological systems: individual cells process information through biochemical networks but cannot maintain computational history beyond their immediate state.

These computational limitations can be transcended through two fundamental capabilities that emerge naturally in both modern AI systems and biological organisms:

First, recursive state maintenance: the ability to maintain and update computational state through step-by-step processing. While underlying systems sacrifice true sequential computation for efficiency, they can simulate sequential processing through recursive reasoning.

Second, history access: the ability to reference and utilize previous computational states. This manifests through attention mechanisms in transformers, episodic memory in biological systems, or external memory systems.

These capabilities combine to enable universal computation in a remarkably simple way. When a system can maintain state recursively and access its computational history through any reliable means, it can implement the basic operations of a Universal Turing Machine.

\section{Basic Requirements and Construction}
A system has recursive state processing if it can read its current state $s$, generate an update function $f(s)$ that produces the next state, and maintain the new state $f(s)$ for subsequent processing.

A system has reliable history access if it can reference any previous state $s_i$ from its computation history, distinguish between different states in its history, and determine the order of states in its history. The system need not maintain its entire history in active memory, only provide reliable access when needed.

These capabilities enable universal computation through a straightforward construction. Given a Universal Turing Machine $U$, we implement it as follows: The state $s = (q, p, a)$ encodes the current machine state $q$, the position $p$ of the tape head, and the symbol $a$ under the head. At each step, the system processes current state $s$ to determine $(q', a', d) = \delta(q, a)$, where $q'$ is the next machine state, $a'$ is the symbol to write, and $d$ is the head movement. It uses history access to reconstruct tape contents as needed and maintains the new state for the next step.

\section{Completeness of the Construction}

\begin{theorem}[Completeness]
Any system $S$ with recursive state maintenance and reliable history access can simulate a Universal Turing Machine with at most logarithmic overhead in space and time complexity.
\end{theorem}

\begin{proof}
We proceed in three steps:

First, we show that $S$ can implement the basic operations of a UTM. Let $M$ be a UTM with state set $Q$, tape alphabet $\Gamma$, and transition function $\delta$. We construct a simulation in $S$ as follows:

State Encoding: Each configuration of $M$ is encoded as a tuple $s = (q, p, a, t)$ where $q \in Q$ is the current machine state, $p \in \mathbb{N}$ is the head position, $a \in \Gamma$ is the symbol under the head, and $t \in \mathbb{N}$ is the step counter.

Tape Simulation: For each position $p$ visited by $M$, we maintain a history entry $h_p = (p, a_p, t_p)$ where $a_p \in \Gamma$ is the symbol written at position $p$ and $t_p$ is the time step when this symbol was written.

Second, we prove that these operations preserve computational state correctly through the following invariants:

\begin{lemma}[State Coherence]
At each step $t$, the simulated configuration $(q, p, a)$ exactly matches the configuration of $M$ after $t$ steps on the same input.
\end{lemma}

\begin{proof}
By induction on $t$:
Base case ($t=0$): The initial configuration matches by construction.
Inductive step: Assume the invariant holds for step $t$. For step $t+1$: $S$ reads current state $(q, p, a, t)$, computes $(q', a', d) = \delta(q, a)$, updates position $p' = p + d$, uses history access to find $a''$ at $p'$, and maintains new state $(q', p', a'', t+1)$. This exactly mirrors $M$'s transition function, preserving the invariant.
\end{proof}

\begin{lemma}[History Consistency]
For any position $p$ and time $t$, the symbol recorded in history matches what would be on $M$'s tape at position $p$ at time $t$.
\end{lemma}

\begin{proof}
We maintain two invariants: each write operation creates a history entry with the current time step, and when reading position $p$, we retrieve the entry with maximum $t_p \leq t$. This ensures we always see the most recent write to each position, exactly matching $M$'s tape contents.
\end{proof}

Finally, we establish the complexity bounds. The simulation incurs logarithmic overhead:
Space: $O(\log t)$ bits for step counter and $O(\log n)$ bits for position encoding
Time: $O(\log t)$ for history access operations

These bounds are tight, as shown in subsequent sections. Therefore, $S$ simulates $M$ with logarithmic overhead in both space and time.
\end{proof}

\begin{corollary}[Universality]
Any system with recursive state maintenance and reliable history access is Turing-complete.
\end{corollary}

\section{Fundamental Constraints of Parallel Training}

The restriction of neural architectures to $\text{TC}_0$ complexity isn't merely an implementation artifact - it emerges necessarily from the requirements of parallel training at scale. To understand why, we must examine the fundamental independence assumptions required for parallel optimization.

Consider a neural network trained on multiple devices. For training to proceed efficiently in parallel, the computation graph must permit independent parameter updates across different portions of the network. This requirement manifests differently across architectures but always imposes similar computational constraints. In transformers, the attention mechanism enables parallel processing by treating each position independently modulo the attention weights. In convolutional networks, the locality assumption enables parallel computation across the spatial dimension. Even recurrent architectures, when unrolled for parallel training, must make independence assumptions between time steps.

These independence assumptions, while crucial for training efficiency, fundamentally limit the network's ability to implement sequential computation in a single forward pass. Merrill \& Sabharwal (2024) proved this rigorously for transformers by showing that any computation requiring true sequential dependence cannot be implemented in a single forward pass through a parallel-trained network. Their proof generalizes naturally to other architectures that rely on similar independence assumptions for parallel training.

The necessity of these constraints becomes clear when we examine the backwards pass during training. Consider a hypothetical architecture that could implement arbitrary sequential computation in a single forward pass. The backwards pass would require propagating gradients through this sequential computation, creating an inherently serial process that would negate the benefits of parallel training. This demonstrates that the $\text{TC}_0$ limitation isn't just a current engineering constraint - it's a necessary consequence of parallel trainability.

\section{Computation in Biological Systems}

The central dogma of molecular biology reveals a fundamental truth about cellular computation: it operates entirely through parallel molecular interactions. Every aspect of information processing in the cell occurs through simultaneous reactions governed by concentration thresholds and binding affinities. Gene regulation involves transcription factors binding and unbinding in parallel across the genome, with enhancers and repressors operating simultaneously to control gene expression. Protein synthesis proceeds through multiple ribosomes translating mRNA concurrently. Even signal transduction, often depicted as a cascade, actually operates through vast networks of kinases and phosphatases simultaneously modifying their targets.

This parallel processing isn't an implementation choice - it's fundamental to cellular metabolism. A cell cannot afford to serialize its basic information processing. The need for metabolic efficiency forces parallel computation just as training efficiency forces parallelism in artificial neural networks. This parallel architecture restricts cellular computation to $\text{TC}_0$ complexity: threshold functions operating on many inputs simultaneously, but no true sequential logic.

Recent experimental work confirms these computational bounds. Studies of the p53 pathway by Batchelor et al. (2023) revealed that while cells excel at implementing complex threshold functions through protein interactions, they cannot maintain ordered sequences of states without specialized structures. The MAP kinase pathway, despite its sophisticated signal processing capabilities, operates entirely through parallel protein modifications and threshold-based state changes. Even apparently sequential processes like the cell cycle are implemented through parallel molecular networks with threshold-based transitions rather than true sequential computation.

Organisms transcend these limitations through specialized structures and multicellular organization. Neural systems achieve sequential computation through synaptic modifications that maintain state across time. The immune system maintains computational history through specialized memory cells. These solutions mirror how artificial systems overcome their parallel processing limitations through recursive state maintenance rather than by making their basic computational units more complex.

\section{Practical Implications}

Understanding computation through the lens of recursive state maintenance fundamentally changes how we should approach both the design and use of AI systems. The parallel processing limitations we've identified aren't engineering obstacles to be overcome - they're fundamental constraints that shape how these systems must operate to achieve complex reasoning.

Traditional approaches to improving AI capabilities have focused on scaling parallel processing power - larger models, more sophisticated attention mechanisms, deeper networks. Our analysis suggests this approach, while useful for pattern matching capabilities, cannot address the fundamental limitations of sequential reasoning. Just as biological systems don't solve sequential computation by making cells more complex, we won't solve it by making transformer layers more sophisticated.

Instead, architectural innovation should focus on robust mechanisms for state maintenance and recursive processing. This might involve memory systems that maintain coherent state across multiple processing steps. State verification mechanisms that ensure consistency across recursive processing steps, similar to how biological systems maintain state coherence through specialized cellular structures.

The implications for system interaction are equally profound and immediately practical. When interacting with language models, we're not dealing with a system that "thinks" in a single forward pass. Instead, we're engaging with a computational process that must build up complex reasoning through recursive state refinement.

This explains why certain interaction patterns prove particularly effective. Chain-of-thought prompting works not because it teaches the model to reason, but because it provides a framework for recursive state maintenance. The model isn't learning new capabilities during the interaction - it's being given a structure for maintaining computational state across multiple steps.

\section{Conclusion}

Understanding computation through these basic requirements clarifies both theoretical bounds and practical system behavior across artificial and biological domains. The simplicity of these requirements demonstrates that universal computation doesn't require complex machinery---just the ability to process state recursively while maintaining reliable access to computational history.

Our results connect to classical computability theory in an interesting way: while Turing's original analysis showed how complex computation could emerge from simple mechanical operations, our work demonstrates that similar computational power emerges naturally from basic cognitive operations like recursive reasoning and memory access. This suggests a deeper connection between computational and cognitive processes than previously recognized.

This work opens several theoretical directions for future research, including the exploration of space-time tradeoffs in recursive computation and the relationship between attention mechanisms and state maintenance in computational processes. Understanding these connections may yield further insights into both the theory of computation and the nature of reasoning in artificial and biological systems.

\end{document}
